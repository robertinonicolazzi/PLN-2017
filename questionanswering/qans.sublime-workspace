{
	"auto_complete":
	{
		"selected_items":
		[
			[
				"ans",
				"answer_type"
			],
			[
				"lo",
				"log_dict"
			],
			[
				"re",
				"return"
			],
			[
				"log",
				"log"
			],
			[
				"an",
				"answer_type"
			],
			[
				"nou",
				"noum_group"
			],
			[
				"questions",
				"questionanswering"
			],
			[
				"rs",
				"rs_entity"
			],
			[
				"corre",
				"correctas_agg"
			],
			[
				"st_p",
				"st_place"
			],
			[
				"st_",
				"st_subproperty"
			],
			[
				"sub",
				"sub_prop"
			],
			[
				"de",
				"default_comparatives"
			],
			[
				"q",
				"q_id"
			],
			[
				"tem",
				"template_ans"
			],
			[
				"str",
				"strip"
			],
			[
				"key",
				"key_st"
			],
			[
				"st",
				"st_ket_f"
			],
			[
				"get",
				"getNounGroups"
			],
			[
				"ke",
				"keys_restantes_copy"
			],
			[
				"kes",
				"keys_restantes"
			],
			[
				"tran",
				"train_prop_x"
			],
			[
				"resul",
				"result_entities"
			],
			[
				"answer",
				"answer_type"
			],
			[
				"enti",
				"entities"
			],
			[
				"db",
				"dbpedia_group"
			],
			[
				"len",
				"lenEntity"
			],
			[
				"desc",
				"desc_rule"
			],
			[
				"pro",
				"proc_desc_rules"
			],
			[
				"spa",
				"spanish"
			],
			[
				"ques",
				"question_features_test"
			],
			[
				"imp",
				"important_words"
			],
			[
				"k",
				"k"
			],
			[
				"e",
				"e"
			],
			[
				"quest",
				"questionanswering"
			],
			[
				"te",
				"temp_prop_y"
			],
			[
				"res",
				"result_entities"
			],
			[
				"ent",
				"enti"
			],
			[
				"temp",
				"temp_prop_x"
			],
			[
				"Extra",
				"ExtractPhrases"
			],
			[
				"prop",
				"propertyExtractor"
			],
			[
				"entit",
				"entityExtractor"
			],
			[
				"Ext",
				"ExtractPhrases"
			],
			[
				"nlp",
				"nlp_api"
			],
			[
				"train",
				"train_prop_y"
			],
			[
				"tra",
				"train_prop_x"
			],
			[
				"Propert",
				"propertyExtractor"
			],
			[
				"bo",
				"boolean"
			],
			[
				"spar",
				"sparqlEn"
			],
			[
				"resour",
				"resource_answerer"
			],
			[
				"answ",
				"answers"
			],
			[
				"en",
				"en_ent"
			],
			[
				"es",
				"es_ent"
			],
			[
				"get_e",
				"get_english_dbpedia"
			],
			[
				"foun",
				"found_entities"
			],
			[
				"chec",
				"check_ent_dbES"
			],
			[
				"eti",
				"entities_total"
			],
			[
				"pr_en",
				"pr_entity_es"
			],
			[
				"sn",
				"sn_entity_en"
			],
			[
				"get_pro",
				"get_question_property"
			],
			[
				"que",
				"question"
			],
			[
				"engl",
				"english_get"
			],
			[
				"hay",
				"hayNames"
			],
			[
				"try",
				"try_english"
			],
			[
				"amb",
				"amb_text"
			],
			[
				"entt",
				"entity"
			],
			[
				"pr_",
				"pr_entity_es"
			],
			[
				"sele",
				"selected_uri"
			],
			[
				"questio",
				"question_features_test"
			],
			[
				"q_",
				"q_clean"
			],
			[
				"tu",
				"True"
			],
			[
				"inde",
				"indextipo"
			],
			[
				"boo",
				"bool_key"
			],
			[
				"bool",
				"boolDirectEnglish"
			],
			[
				"agre",
				"aggregation"
			],
			[
				"proip",
				"properties"
			],
			[
				"prope",
				"properti"
			],
			[
				"entidad",
				"entidad_elegida"
			],
			[
				"a",
				"answertype"
			],
			[
				"def",
				"default_ans"
			],
			[
				"s",
				"st_property"
			],
			[
				"qe",
				"question_features_test"
			],
			[
				"tag",
				"tag_word"
			],
			[
				"piep",
				"pipeline"
			],
			[
				"nl",
				"nlp_api"
			],
			[
				"keys",
				"keys_restantes"
			],
			[
				"clean",
				"cleanQuestion"
			],
			[
				"tagge",
				"tagged_keywords"
			],
			[
				"parser",
				"parserSample"
			],
			[
				"tagg",
				"tagged_keywords"
			],
			[
				"spli",
				"split_comma"
			],
			[
				"clas",
				"clas_propiedades"
			],
			[
				"fea",
				"features_bag_of_words"
			],
			[
				"feature",
				"features_bag_of_words"
			],
			[
				"sus",
				"sustComunes"
			],
			[
				"emp",
				"empiezaConPreposicion"
			],
			[
				"string",
				"string_list"
			],
			[
				"resE",
				"resElegido"
			],
			[
				"dbo",
				"dboElegido"
			],
			[
				"keywo",
				"keywords"
			],
			[
				"tagged",
				"tagged_keywords"
			],
			[
				"w",
				"where"
			],
			[
				"se",
				"select"
			],
			[
				"verb",
				"verbos"
			],
			[
				"keywor",
				"keywords_pro"
			],
			[
				"keo",
				"keywords_verb"
			],
			[
				"keyw",
				"keywords_verb"
			],
			[
				"ta",
				"tagged_sent"
			],
			[
				"class",
				"classify"
			],
			[
				"test",
				"test_sentence"
			],
			[
				"test_",
				"test_sent_features"
			],
			[
				"strin",
				"string_question"
			],
			[
				"aux",
				"auxNewVar"
			],
			[
				"gol",
				"gold_parsed_sent"
			],
			[
				"eva",
				"evalBool"
			],
			[
				"tre",
				"tree_temp"
			],
			[
				"parse",
				"parsed_sents"
			],
			[
				"resu",
				"result_tree"
			],
			[
				"pi",
				"pi_y"
			],
			[
				"prob",
				"probs_dict"
			],
			[
				"clasi",
				"clasificador"
			],
			[
				"his",
				"histories"
			],
			[
				"total",
				"total"
			],
			[
				"matri",
				"matrix_confusion"
			],
			[
				"matrix",
				"matrix_confusion"
			],
			[
				"most",
				"most_frequent_taq"
			],
			[
				"confusio",
				"confusion_matrix"
			],
			[
				"in",
				"inf"
			]
		]
	},
	"buffers":
	[
		{
			"contents": "# -*- coding: utf-8 -*-\n#!/usr/bin/python\n\nfrom SPARQLWrapper import SPARQLWrapper, JSON\nfrom questionanswering.funaux import *\nfrom questionanswering.booleanHelper import BooleanHelper\nfrom questionanswering.aggregationHelper import AggregationHelper\nfrom questionanswering.entityExtractor import EntityExtractor\nfrom questionanswering.propertyExtractor import PropertyExtractor\nfrom questionanswering.templates import *\nimport sys\nimport json\nimport re\nimport nltk\nimport nltk.classify.util\nimport numpy as np\nimport spacy\n\n\ndef progress(msg, width=None):\n    \"\"\"Ouput the progress of something on the same line.\"\"\"\n    if not width:\n        width = len(msg)\n    print('\\b' * width + msg, end='')\n    sys.stdout.flush()\n\n\nclass ClassAnswerType:\n\n    def __init__(self, questions, propCorpus=[[], []], nlp=None):\n\n        self.nlp_api = nlp\n        self.sparql = SPARQLWrapper(\"http://es.dbpedia.org/sparql\")\n        self.sparql.setReturnFormat(JSON)\n        self.sparqlEn = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n        self.sparqlEn.setReturnFormat(JSON)\n        self.pExtractor = PropertyExtractor(self.nlp_api)\n        train_prop_x = []\n        train_prop_y = []\n        self.all_words = set()\n\n        train_answer_type = []\n        keys = []\n        dbo = []\n        format_str = 'Answ Type ({}/{}) (Preg={}, Total={}), Prop {} '\n\n        progress(format_str.format(0, len(questions), 0, len(questions), 0))\n\n        i = 0\n        j = 0\n        for quest in questions:\n            i += 1\n            idiomas = quest[\"question\"]\n            st_keywords = \"\"\n            st_question = \"\"\n            for idiom in idiomas:\n                if idiom[\"language\"] == \"es\":\n                    st_question = idiom[\"string\"]\n                    st_keywords = idiom[\"keywords\"]\n                    break\n            if st_question == \"\":\n                continue\n\n            # Generamos features para tipo de respuesta\n            feat_question = self.features_answer_type(st_question)\n            st_answer_type = quest[\"answertype\"]\n\n            train_answer_type.append((feat_question, st_answer_type))\n\n            # Intento de mapeo de propiedades\n\n            temp_train_x, temp_train_y = self.pExtractor.generate_train_by_entity(\n                quest[\"query\"][\"sparql\"], st_keywords)\n            if not len(temp_train_x) == 0:\n                j += 1\n            progress(\n                format_str.format(\n                    i,\n                    len(questions),\n                    i,\n                    len(questions),\n                    j))\n            train_prop_x += temp_train_x\n            train_prop_y += temp_train_y\n\n        self.clas_tipo = nltk.NaiveBayesClassifier.train(train_answer_type)\n\n        self.pExtractor.train(train_prop_x, train_prop_y, propCorpus)\n        self.eExtractor = EntityExtractor(self.nlp_api)\n\n    # -------------------------------------------------------------\n    # --GET ANSWER TYPE--------------------------------------------\n    # -------------------------------------------------------------\n\n    def get_answer_type(self, st_question):\n\n        question_features_test = self.features_answer_type(st_question)\n\n        type_question = self.clas_tipo.classify(question_features_test)\n        return type_question\n\n    def features_answer_type(self, st_question):\n        feat = {}\n        st_question = cleanQuestion(st_question)\n        tag_word = self.nlp_api(st_question)\n\n        tag_word = [(word.text, word.tag_) for word in tag_word]\n        # print(tag_word)\n\n        feat[\"ask_cuanto\"] = bool(\n            re.search(\n                'cu(a|á)nt(o|a)(s|) ',\n                st_question))\n        feat[\"init_dame\"] = (st_question.split(\" \")[0] == 'dame')\n        feat[\"ask_cuando\"] = bool(re.search('cu(a|á)ndo ', st_question))\n        feat[\"init_verb\"] = 'VERB' in getFirstTag(\n            tag_word) or 'AUX' in getFirstTag(tag_word)\n\n        second_tag = getSecondTag(tag_word)\n        articulo = 'PronType=Art' in getFirstTag(\n            tag_word) and 'DET' in getFirstTag(tag_word)\n\n        feat[\"art_sust2\"] = articulo and (\n            ('NOUN' in second_tag) or (\n                'PROPN' in second_tag))\n\n        #feat[\"init_verb2\"]  = getFirstTag(tag_word) == 'VERB'\n        #feat[\"art_sust\"]   = (getFirstTag(tag_word) == 'DET') and (second_tag== 'NOUN' or second_tag=='PROPN')\n        return feat\n\n    # -------------------------------------------------------------\n    # --GET SIMPLE ANSWERS WORKFLOW -------------------------------\n    # -------------------------------------------------------------\n    def default_ans(self, entity, answertype):\n        sparql = self.sparqlEn\n        answers = []\n        properti = \"\"\n        if answertype == \"date\":\n            properti = \"date\"\n\n        query = '''\n\t\t\t\tselect distinct ?result\n\t\t\t\twhere {{\n\t\t\t\t\t<http://dbpedia.org/resource/{}> dbp:{} ?result\n\t\t\t\t}}\n\t\t\t\t'''.format(entity, properti)\n\n        answers = resolveQuery(sparql, query)\n\n        return set(answers)\n\n    def get_english_ans_reverse(self, entity, properti):\n        sparql = self.sparqlEn\n        query = templates.get('simple_rev',\"\")\n        query = query.format(res=entity, prop=properti)\n        answers = resolveQuery(sparql, query)\n        return set(answers)\n\n    def get_english_ans(self, entity, properti):\n        sparql = self.sparqlEn\n        query = templates.get('simple',\"\")\n        query = query.format(res=entity, prop=properti)\n        answers = resolveQuery(sparql, query)\n\n        if len(answers) == 0:\n            query = templates.get('simple_amb',\"\")\n            query = query.format(res=entity, prop=properti)\n            answers = resolveQuery(sparql, query)\n        return set(answers)\n\n    # -----------------------------------------------------------------------\n    # ---------------------- PREGUNTAS BOOLEAN ------------------------------\n    # -----------------------------------------------------------------------\n\n    def boolean_answerer(self, q, q_keys):\n\n        pr_entity_es = \"\"\n        sn_entity_es = \"\"\n        answers = False\n        q = cleanQuestion(q)\n        h_boolean = BooleanHelper()\n\n        entities, k_rest = self.eExtractor.get_entities(\n            q_keys, 'boolean')\n        if len(entities) == 0:\n            print(\"Entities not Found\")\n            return []\n        print(\"Entidades     : \", entities)\n        print(\"Keys Restantes: \", k_rest)\n\n        if len(entities) == 1:\n            pr_entity_es = entities[0][0]\n            pr_entity_en = entities[0][1]\n\n            bool_key, properti = h_boolean.boolean_key_one_entity(q)\n            print(\"Bool_key:\", bool_key)\n            print(\"PropertiTemp:\", properti)\n            if bool_key == \"type\":\n                answers = h_boolean.get_type_answer(pr_entity_es, properti)\n            elif bool_key == \"exist\":\n                answers = h_boolean.get_exist_answer(pr_entity_es, properti)\n            else:\n                properti = self.pExtractor.get_question_property(\n                    pr_entity_en, k_rest)\n                answers = h_boolean.get_properti_answer(pr_entity_en, properti)\n\n        elif len(entities) == 2:\n\n            pr_entity_en = entities[0][1]\n            sn_entity_en = entities[1][1]\n\n            props, st_filter = self.two_entities_prop_filter(\n                q, pr_entity_en, sn_entity_en, k_rest)\n\n            if props == \"\":\n                return []\n\n            answers = h_boolean.two_entities_answer(\n                pr_entity_en, sn_entity_en, props, st_filter)\n        else:\n            answers = []\n\n        return answers\n\n    def two_entities_prop_filter(\n            self, question, entity, sn_entity, k_rest):\n        prop = \"\"\n        st_filter = \"\"\n        if \"antes\" in question:\n            st_filter = \"FILTER (?x < ?y)\"\n            prop = \"date\"\n        elif \"despues\" in question:\n            st_filter = \"FILTER (?x > ?y)\"\n            prop = \"date\"\n        elif \"menor\" in question:\n            st_filter = \"FILTER (?x < ?y)\"\n            prop = self.pExtractor.get_question_property(entity, k_rest)\n            if prop == \"\":\n                prop = self.pExtractor.get_question_property(sn_entity, k_rest)\n        elif \"mayor\" in question or \"grande\" in question:\n            st_filter = \"FILTER (?x > ?y)\"\n            prop = self.pExtractor.get_question_property(entity, k_rest)\n            if prop == \"\":\n                prop = self.pExtractor.get_question_property(sn_entity, k_rest)\n        elif \"misma\" in question or \"igual\" in question or \"mismos\" in question:\n            st_filter = \"same\"\n            prop = self.pExtractor.get_question_property(entity, k_rest)\n            if prop == \"\":\n                prop = self.pExtractor.get_question_property(sn_entity, k_rest)\n        else:\n            prop = self.pExtractor.get_question_property(entity, k_rest)\n            if prop == \"\":\n                prop = self.pExtractor.get_question_property(sn_entity, k_rest)\n            # la igualdad es viendo si pertenece\n            st_filter = \"\"\n\n        return prop, st_filter\n\n    # ------------------------------------------------------------------------\n    # ---------------------- RESPONDER PREGUNTAS -----------------------------\n    # ------------------------------------------------------------------------\n\n    def answer_question(self, q, q_keys,log=False):\n\n        log_dict = {}\n\n        print('---------------------------------------------------------------')\n\n        answers = []\n        answer_type = self.get_answer_type(q)\n\n        print('{:15} | {}'.format('QUESTION: ', q))\n        print('{:15} | {}'.format('ANSWER TYPE: ', answer_type))\n\n        if answer_type == \"boolean\":\n            return self.boolean_answerer(q, q_keys)\n\n        h_agg = AggregationHelper(nlp=self.nlp_api)\n        keyAggregation = h_agg.check_aggregation(answer_type, q, q_keys)\n\n        if not keyAggregation == \"none\":\n            return self.aggregation_answerer(\n                h_agg, q, q_keys, keyAggregation, answer_type)\n\n        entities, k_rest = self.eExtractor.get_entities(\n            q_keys, answer_type)\n\n        if len(entities) == 0:\n            print(\"Entities not Found\")\n            return []\n\n        print(\"Entidades     : \", entities)\n        print('{:15} | {:10}'.format(\"1 Keys\", \"|\".join(k_rest)))\n\n        es_entity = entities[0][0]\n        en_entity = entities[0][1]\n\n        st_property = self.pExtractor.get_question_property(\n            en_entity, k_rest)\n\n        print(\"Entidad Espanol:\", es_entity)\n        print(\"Entidad Ingles :\", en_entity)\n        print(\"Propiedad      :\", st_property)\n\n        answers = self.get_english_ans(en_entity, st_property)\n        print(\"Respuesta:\", answers)\n\n        if len(answers) == 0 and answer_type == \"date\":\n            answers = self.default_ans(en_entity, answer_type)\n\n        if len(answers) == 0 and answer_type == \"resource\":\n            print(\"Reverse\")\n            st_property = self.pExtractor.get_question_property_rev(\n                en_entity, k_rest)\n            answers = self.get_english_ans_reverse(en_entity, st_property)\n\n        print('---------------------------------------------------------------')\n\n        log_dict[\"answer_type\"] = answer_type\n        log_dict[\"entity\"] = \"ES: \"+es_entity + \" | EN: \" + en_entity\n        log_dict[\"property\"] = st_property\n        log_dict[\"answers\"] = \"\\n\".join([a for a in answers])\n\n        if log:\n            return log_dict\n\n        return answers\n\n    def aggregation_answerer(self, h_agg, q,\n                             q_keys, key, answer_type):\n        q_keys = delete_tildes(q_keys)\n        answers = []\n        if key == \"count\":\n            entities, k_rest = self.eExtractor.get_entities(\n                q_keys,\n                answer_type\n            )\n            if len(entities) == 0:\n                print(\"Entities not Found\")\n                return []\n            print(\"Entidades     : \", entities)\n            print(\"Keys Restantes: \", k_rest)\n\n            es_entity = entities[0][0]\n            en_entity = entities[0][1]\n\n            st_property = self.pExtractor.get_question_property(\n                en_entity, k_rest)\n            answers = self.get_english_ans(en_entity, st_property)\n            if key == \"count\" and not len(answers) == 0:\n                if 'resource' in list(answers)[0]:\n                    answers = h_agg.get_aggregation_count(\n                        en_entity, st_property)\n\n        if \"asc\" in key or \"desc\" in key:\n            entities, k_rest = self.eExtractor.get_entities(\n                q_keys, answer_type)\n\n            #import pdb; pdb.set_trace()\n            st_place = \"\"\n            if len(entities) == 1:\n                st_place, k_rest = h_agg.check_entity(\n                    entities[0], q_keys, k_rest)\n                if not st_place == \"\":\n                    print('{:15} | {:10}'.format(\"Lugar\", st_place))\n                    entities = []\n            if len(entities) == 0:\n                st_property = \"\"\n                k_rest, st_subproperty = h_agg.get_sub_property(\n                    key, k_rest)               \n                print('{:15} | {:10}'.format(\"SubPropiedad\", st_subproperty))\n                print('{:15} | {:10}'.format(\"1 Keys\", \",\".join(k_rest)))\n\n                st_type, k_rest = h_agg.get_type(k_rest)\n                print('{:15} | {:10}'.format('Tipo Entidad', st_type))\n                print('{:15} | {:10}'.format(\"2 Keys\", \",\".join(k_rest)))\n\n                if not len(k_rest) == 0:\n                    st_property = self.pExtractor.get_question_property_type(\n                        st_type, k_rest)\n\n                if st_property == \"\":\n                    if len(answers) == 0:\n                        for st_property in h_agg.get_default(\n                                st_subproperty):\n                            answers = h_agg.get_aggregation_order_type(\n                                st_type, st_property, key)\n                            if not len(answers) == 0:\n                                break\n                else:\n                    if not st_place == \"\":\n                        answers = h_agg.get_aggregation_order_type_place(\n                            st_type, st_property, key, st_place)\n                    else:\n                        answers = h_agg.get_aggregation_order_type(\n                            st_type, st_property, key)\n\n\n            else:\n                # Tenemos la Entidad\n                es_entity = entities[0][0]\n                en_entity = entities[0][1]\n\n                # Obtenemos la subpropiedad para comparar los resultados\n                # child--BirthDate\n                k_rest, st_subproperty = h_agg.get_sub_property(\n                    key, k_rest)                \n\n                # Vemos que se quiere saber de la entidad (propiedad) Ej:\n                # Hijos--child\n                st_property = self.pExtractor.get_question_property(\n                    en_entity, k_rest)\n\n                print('{:15} | {:10}'.format('Entidad', en_entity))\n                print('{:15} | {:10}'.format(\"SubPropiedad\", st_subproperty))\n                print('{:15} | {:10}'.format(\"Keys Restantes\", \"|\".join(k_rest)))\n                print('{:15} | {:10}'.format(\"Propiedad\", st_property))\n\n                answers = h_agg.get_subprop_answer(\n                    en_entity, st_property, st_subproperty, key)\n                if len(answers) == 0:\n                    for st_sub in h_agg.get_default(st_subproperty):\n                        answers = h_agg.get_subprop_answer(\n                            en_entity, st_property, st_sub, key)\n                        if not len(answers) == 0:\n                            break\n        print(\"Respuesta:\", answers)\n        return set(answers)\n",
			"file": "main.py",
			"file_size": 15762,
			"file_write_time": 131544605130000821,
			"settings":
			{
				"buffer_size": 15759,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "entityExtractor.py",
			"settings":
			{
				"buffer_size": 4842,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "scripts/testQuestion.py",
			"settings":
			{
				"buffer_size": 1714,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"file": "scripts/gen.py",
			"settings":
			{
				"buffer_size": 950,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		},
		{
			"contents": "['0', '2', '3', '4', '5', '6', '7', '9', '10', '11', '12', '13', '17', '18', '19', '20', '21', '22', '23', '24', '25', '28', '29', '30', '31', '32', '33', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '48', '49', '50', '52', '54', '55', '58', '59', '60', '61', '63', '64', '65']\n\n",
			"settings":
			{
				"buffer_size": 294,
				"line_ending": "Unix",
				"name": "['0', '2', '3', '4', '5', '6', '7', '9', '10', '11"
			}
		},
		{
			"file": "scripts/eval.py",
			"settings":
			{
				"buffer_size": 4804,
				"encoding": "UTF-8",
				"line_ending": "Unix"
			}
		}
	],
	"build_system": "",
	"build_system_choices":
	[
	],
	"build_varint": "",
	"command_palette":
	{
		"height": 159.0,
		"last_filter": "",
		"selected_items":
		[
			[
				"Package Control: instal",
				"Package Control: Install Package"
			],
			[
				"python",
				"Python Breakpoints: Clear All"
			],
			[
				"packka",
				"Package Control: Install Package"
			],
			[
				"pac",
				"Preferences: Browse Packages"
			]
		],
		"width": 497.0
	},
	"console":
	{
		"height": 153.0,
		"history":
		[
			"import urllib.request,os,hashlib; h = '6f4c264a24d933ce70df5dedcf1dcaee' + 'ebe013ee18cced0ef93d5f746d80ef60'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)",
			"import urllib.request,os,hashlib; h = 'df21e130d211cfc94d9b0905775a7c0f' + '1e3d39e33b79698005270310898eea76'; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); by = urllib.request.urlopen( 'http://packagecontrol.io/' + pf.replace(' ', '%20')).read(); dh = hashlib.sha256(by).hexdigest(); print('Error validating download (got %s instead of %s), please try manual install' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), 'wb' ).write(by)"
		]
	},
	"distraction_free":
	{
		"menu_visible": true,
		"show_minimap": false,
		"show_open_files": false,
		"show_tabs": false,
		"side_bar_visible": false,
		"status_bar_visible": false
	},
	"expanded_folders":
	[
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/Data",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/Log",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/scripts"
	],
	"file_history":
	[
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/interfaz.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/customTrain.json",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/templates.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/GUI/back.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/GUI/main.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/GUI/index.html",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/funaux.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/TrainData.json",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/Log/complex.log",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/scripts/gen.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/qans.sublime-project",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/SimpleData.json",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/scripts/train.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/Log/simple.log",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/Log/aggregation.log",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/aggregationHelper.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/main.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/Log/bool.log",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/myfile",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/booleanHelper.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/propertyExtractor.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/Data/types",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/scripts/eval.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/entityExtractor.py",
		"/media/robertnn/DatosLinux/SimpleDataCopy",
		"/home/robertnn/Descargas/project_21812_citations.txt",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/helpers.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/codigoExtra.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/scripts/testprop.py",
		"/media/robertnn/DatosLinux/ProyectosOpenGL/GameEngine/Shaders/shader.cpp",
		"/home/robertnn/.bashrc",
		"/home/robertnn/.cache/.fr-yQcNQE/readme.txt",
		"/home/robertnn/Downloads/es core web md-1/es_core_web_md-1.0.0/es_core_web_md/es_core_web_md-1.0.0/pos/model",
		"/home/robertnn/Downloads/es core web md-1/es_core_web_md-1.0.0/es_core_web_md/es_core_web_md-1.0.0/pos/config.json",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/SimpleDataOri",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/SimplesLog",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/out.txt",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/simple_questions.csv",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/scripts/testQuestion.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/EvalData.json",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/scripts/evalDev.py",
		"/media/robertnn/DatosLinux/PLN-2017/questionanswering/script.sh",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/scripts/eval.py",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/interfaz.py",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/main.py",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/scripts/train.py",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/funaux.py",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/TrainData.json",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/codigoExtra.py",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/scripts/train.py",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/scripts/eval.py",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/tests/test_cky_parser.py",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/cky_parser.py",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/upcfg.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/scripts/train.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/hmm.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/memm.py",
		"/media/robertnn/DatosLinux/PLN-2017/pruebas/script.sh",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/scripts/eval.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/tests/test_hmm.py",
		"/media/robertnn/DatosLinux/PLN-2017/languagemodeling/scripts/train.py",
		"/home/robertnn/Descargas/code_document_classify_use.py",
		"/media/robertnn/DatosLinux/PLN-2017/main.py",
		"/home/robertnn/.cache/.fr-riirBY/sparqlwrapper-1.7.6/README.md",
		"/media/robertnn/DatosLinux/Facultad/PLN/ProyectoFinal/data.json",
		"/media/robertnn/Datos1/History.txt",
		"/media/robertnn/Datos1/Desarrollo-Programas/ogldev-source/tutorial50/tutorial50.cpp",
		"/media/robertnn/Datos1/x64Bits/Serial.txt",
		"/home/robertnn/Dropbox/ej3.py",
		"/home/robertnn/Desktop/boolean_descomposition_SBox.c",
		"/home/robertnn/Desktop/det.py",
		"/home/robertnn/Desktop/matrix.c",
		"/home/robertnn/Desktop/differential_criptoanalisis.py",
		"/home/robertnn/Desktop/ej2Cripto.py",
		"/home/robertnn/Descargas/test.txt",
		"/home/robertnn/Descargas/te2.py",
		"/home/robertnn/Desktop/bit.c",
		"/home/robertnn/Desktop/cripto.py",
		"/home/robertnn/Desktop/branch.py",
		"/home/robertnn/Criptografia/homework1/chiper.c",
		"/home/robertnn/Criptografia/homework1/asd.txt",
		"/home/robertnn/Descargas/ej8.als",
		"/home/robertnn/Descargas/TAATARATAAA.txt",
		"/home/robertnn/.cache/.fr-mx13FX/Lang.hs",
		"/home/robertnn/.cache/.fr-brEmoS/Examples.hs",
		"/home/robertnn/.cache/.fr-u9uujF/Eval.hs",
		"/home/robertnn/.cache/.fr-6z7ODw/State.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/Proyecto-Compiladores/Main.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/archivo/Eval.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/archivo/Examples.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/archivo/Lang.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/archivo/State.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/archivo/Main.hs",
		"/home/robertnn/Descargas/Examples.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/Proyecto-Compiladores/Eval.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/Proyecto-Compiladores/Examples.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/Proyecto-Compiladores/State.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/IngII/2daParte/Practico_6/ej09.als",
		"/media/robertnn/DatosLinux/SharedWINLIN/IngII/2daParte/Practico_6/ej10.als",
		"/home/robertnn/Descargas/ej8 (1).als",
		"/media/robertnn/DatosLinux/SharedWINLIN/IngII/2daParte/Practico_6/ej08.als",
		"/media/robertnn/DatosLinux/SharedWINLIN/IngII/2daParte/Practico_6/ej07.als",
		"/media/robertnn/DatosLinux/SharedWINLIN/IngII/8-El_lenguaje_de_especificacion_Alloy_Examples/Ejercicios/ej4.als",
		"/etc/samba/smb.conf",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/README.md",
		"/media/robertnn/DatosLinux/SharedWINLIN/IngII/8-El_lenguaje_de_especificacion_Alloy_Examples/Ejercicios/ej5.als",
		"/run/user/1000/gvfs/sftp:host=mail.famaf.unc.edu.ar,user=ron0113/home/ron0113/ej7.als",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/util.py",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/baselines.py",
		"/media/robertnn/DatosLinux/SharedWINLIN/ProyectoFinal.tex",
		"/media/robertnn/DatosLinux/SharedWINLIN/Proyecto-Compiladores/Lang.hs",
		"/media/robertnn/DatosLinux/SharedWINLIN/Proyecto-Compiladores/ProyectoSublime.sublime-project",
		"/home/robertnn/sudo",
		"/home/robertnn/vi",
		"/media/robertnn/DatosLinux/PLN-2017/parsing/tests/test_util.py",
		"/media/robertnn/DatosLinux/PLN-2017/.gitignore",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/README.md",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/scripts/stats.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/baseline.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/baseTrained.txt",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/tests/test_memm.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/tests/test_ml_hmm.py",
		"/media/robertnn/DatosLinux/PLN-2017/tagging/features.py",
		"/media/robertnn/DatosLinux/ProyectosExtJS/DirectApp/app/Application.js",
		"/media/robertnn/DatosLinux/ProyectosExtJS/DirectApp/app.json",
		"/media/robertnn/DatosLinux/ProyectosExtJS/DirectApp/app/VideoWindow.js",
		"/media/robertnn/DatosLinux/ProyectosExtJS/DirectApp/index.html",
		"/media/robertnn/DatosLinux/ProyectosExtJS/DirectApp/sass/src/view/main/Main.scss"
	],
	"find":
	{
		"height": 39.0
	},
	"find_in_files":
	{
		"height": 93.0,
		"where_history":
		[
			""
		]
	},
	"find_state":
	{
		"case_sensitive": false,
		"find_history":
		[
			"import pd",
			"h_agg",
			"h_aggregation.",
			"self.entExtractor",
			"self.propExtractor",
			"keys_restantes",
			"self.entityExtractor",
			"self.propertyExtractor",
			"India",
			"población",
			"rio",
			"'",
			"grupos",
			"numero",
			"Queen",
			"\"boolean\"",
			"Monte Ev",
			"Bill Ga",
			"director",
			"Qué",
			"Cuáles",
			"ingredientes",
			"nacimiento",
			"ciudad ",
			"poblacion total",
			"author,pintor",
			"pintor",
			"pdb",
			"BooleanHelper",
			"get_entities",
			"removeStopWords",
			"\"keywords\": \".*\\?\"",
			"height'",
			"height",
			"print",
			"get_english_ans",
			"height",
			"get_entities",
			"res:",
			"get_entities",
			"(\"---------\")",
			"check_aggregation",
			"get_english_dbpedia",
			"Actúa C",
			"BIND",
			"esdbr",
			"get_question_",
			"FILTER",
			"Warcraft",
			"get_named_e",
			"check_entities_espanol",
			"get_english_ans",
			"pilares",
			"Quen",
			"?uri d",
			"get_english_ans",
			"Quién",
			"llamado",
			"llamaba",
			"llamado",
			"check_entitiesE",
			"check_ent",
			"Dame",
			"try_english_name",
			"get_english_dbpedia",
			"ú",
			"ó",
			"í",
			"é",
			"á",
			"boolean",
			"features_answer_type",
			"get_answer_type",
			"La coca Co",
			"Amazon",
			"check_entitiesEsp",
			"Par",
			"class",
			"Cuál fue",
			"default_ans",
			"aggregation\": t",
			"check_entitiesEsp",
			"default_ans",
			"get_english_ans",
			"leaderName",
			"get_entity",
			"get_english_ans",
			"print(",
			"check_entitiesEsp",
			"aggregation\": T",
			"aggregati",
			"Cuántos",
			"get_english_dbpedia",
			"boolean",
			"get_entity",
			"lego",
			"child",
			"get_question_property",
			"get_english_ans",
			"get_question_property",
			"answertype\": \"",
			"deathDate",
			"print",
			"bindin",
			"nlp_ap",
			"Prince",
			"princi",
			"nlp_api",
			"boolean",
			"spouse",
			"birthDa",
			"nació",
			"naci",
			"birth",
			"number",
			"dbo:number",
			"dbo:nu",
			"True",
			"nació",
			"True",
			"Obama",
			"spouse",
			"obtener_propiedad",
			"question_ty",
			"self.question_features",
			"self.classifier",
			"Es",
			"answertype\": \"date\""
		],
		"highlight": true,
		"in_selection": false,
		"preserve_case": false,
		"regex": true,
		"replace_history":
		[
			"h_agg.",
			"self.eExtractor",
			"self.pExtractor",
			"k_rest",
			"self.entExtractor",
			"self.propExtractor",
			"\"",
			"\"keywords\": \".*\"",
			"u",
			"o",
			"i",
			"e",
			"a",
			"self.features_answer_type",
			"self.clas_tipo",
			"Cuándo",
			"Cuántas",
			"Cuánto",
			"},\n\t\t\t\t\t\t{",
			"},\n\t\t\t\t\"results\": {",
			"",
			"\t\t\t\t}\n\t\t\t\t",
			"\\{[^\\\"]*\"language\": \"es\"[^\\}]*\\}",
			"",
			"\"\"",
			"",
			"->",
			"0",
			"salmon",
			"getDesktop",
			"DirectApp",
			"INICIO",
			"FINAL",
			"END",
			"FINAL",
			"INICIO",
			"FINAL",
			"INICIO",
			"evala.cross_entropy",
			"",
			"'",
			"",
			"\\oplus",
			"",
			"\\overline{",
			"W",
			"Z",
			"Y",
			"X",
			"",
			"W",
			"Z",
			"Y",
			"X",
			"\\overline{",
			"\\oplus",
			"",
			"\\oplus",
			"W",
			"Z",
			"Y",
			"X",
			"\\overline{",
			"mat4",
			"mat3",
			"mat2",
			"2",
			"1",
			"0",
			"z",
			"y",
			"x",
			"",
			"(n)",
			"DatosLinux",
			"sublime_text"
		],
		"reverse": false,
		"show_context": true,
		"use_buffer2": true,
		"whole_word": false,
		"wrap": true
	},
	"groups":
	[
		{
			"selected": 0,
			"sheets":
			[
				{
					"buffer": 0,
					"file": "main.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 15759,
						"regions":
						{
						},
						"selection":
						[
							[
								14026,
								14026
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.tmLanguage",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 6210.0,
						"zoom_level": 1.0
					},
					"stack_index": 0,
					"type": "text"
				},
				{
					"buffer": 1,
					"file": "entityExtractor.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4842,
						"regions":
						{
						},
						"selection":
						[
							[
								3286,
								3286
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 1620.0,
						"zoom_level": 1.0
					},
					"stack_index": 5,
					"type": "text"
				},
				{
					"buffer": 2,
					"file": "scripts/testQuestion.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 1714,
						"regions":
						{
						},
						"selection":
						[
							[
								1697,
								1658
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"tab_size": 4,
							"translate_tabs_to_spaces": true
						},
						"translation.x": 0.0,
						"translation.y": 648.0,
						"zoom_level": 1.0
					},
					"stack_index": 3,
					"type": "text"
				},
				{
					"buffer": 3,
					"file": "scripts/gen.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 950,
						"regions":
						{
						},
						"selection":
						[
							[
								950,
								950
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.sublime-syntax",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 4,
					"type": "text"
				},
				{
					"buffer": 4,
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 294,
						"regions":
						{
						},
						"selection":
						[
							[
								0,
								294
							]
						],
						"settings":
						{
							"auto_name": "['0', '2', '3', '4', '5', '6', '7', '9', '10', '11",
							"syntax": "Packages/Text/Plain text.tmLanguage"
						},
						"translation.x": 0.0,
						"translation.y": 0.0,
						"zoom_level": 1.0
					},
					"stack_index": 1,
					"type": "text"
				},
				{
					"buffer": 5,
					"file": "scripts/eval.py",
					"semi_transient": false,
					"settings":
					{
						"buffer_size": 4804,
						"regions":
						{
						},
						"selection":
						[
							[
								2012,
								2012
							]
						],
						"settings":
						{
							"syntax": "Packages/Python/Python.tmLanguage",
							"translate_tabs_to_spaces": false
						},
						"translation.x": 0.0,
						"translation.y": 1080.0,
						"zoom_level": 1.0
					},
					"stack_index": 2,
					"type": "text"
				}
			]
		}
	],
	"incremental_find":
	{
		"height": 26.0
	},
	"input":
	{
		"height": 32.0
	},
	"layout":
	{
		"cells":
		[
			[
				0,
				0,
				1,
				1
			]
		],
		"cols":
		[
			0.0,
			1.0
		],
		"rows":
		[
			0.0,
			1.0
		]
	},
	"menu_visible": true,
	"output.find_results":
	{
		"height": 0.0
	},
	"pinned_build_system": "",
	"project": "qans.sublime-project",
	"replace":
	{
		"height": 64.0
	},
	"save_all_on_build": true,
	"select_file":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_project":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"select_symbol":
	{
		"height": 0.0,
		"last_filter": "",
		"selected_items":
		[
		],
		"width": 0.0
	},
	"selected_group": 0,
	"settings":
	{
	},
	"show_minimap": true,
	"show_open_files": true,
	"show_tabs": true,
	"side_bar_visible": true,
	"side_bar_width": 200.0,
	"status_bar_visible": true,
	"template_settings":
	{
	}
}
